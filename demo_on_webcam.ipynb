{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get video persion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'X264')\n",
    "out = cv2.VideoWriter('Test_persion.mp4',fourcc, 20.0, (640,480))\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret==True:\n",
    "        # frame = cv2.flip(frame,0)\n",
    "        frame = frame[:, :, :]\n",
    "        # write the flipped frame\n",
    "        out.write(frame)\n",
    "\n",
    "        cv2.imshow('frame',frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Release everything if job is finished\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from src.api.tryon.service.dm_vton import DMVTON, get_transform\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "from src.api.tryon.service.u2net import load_model as load_edge_detect_model\n",
    "from src.api.tryon.service.u2net import norm_pred\n",
    "from src.api.tryon.service.yolov7_pose import Yolov7PoseEstimation\n",
    "\n",
    "class Camera():\n",
    "    def __init__(self):\n",
    "        self.video = cv2.VideoCapture(0)\n",
    "\n",
    "    def __del__(self):\n",
    "        self.video.release()\n",
    "\n",
    "    def get_frame(self):\n",
    "        success, image = self.video.read()\n",
    "        # ret, jpeg = cv2.imencode('.jpg', image)\n",
    "        # return jpeg.tobytes()\n",
    "        return success, image\n",
    "    \n",
    "    def isOpened(self):\n",
    "        return self.video.isOpened()\n",
    "    \n",
    "\n",
    "class TryonService:\n",
    "    def __init__(\n",
    "        self, tryon_ckpt, edge_detect_ckpt, yolo_ckpt, device, img_size=(192, 256)\n",
    "    ) -> None:\n",
    "        self.device = device\n",
    "        self.img_size = img_size\n",
    "        self._load_model(tryon_ckpt, edge_detect_ckpt, device=device)\n",
    "        self._load_yolov7(yolo_ckpt)\n",
    "\n",
    "    def tryon_video(self, save_name, cap, pil_clothes, pil_edge=None, fps=30):\n",
    "        transform_image = get_transform(train=False)\n",
    "        transform_edge = get_transform(train=False, method=Image.NEAREST, normalize=False)\n",
    "\n",
    "        # save_name = f'{datetime.datetime.now().strftime(\"%Y-%m-%d_%H%M-%S\")}.mp4'\n",
    "        # save_name = 'output.mp4'\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'X264')\n",
    "        # vid_writer = cv2.VideoWriter(save_name, cv2.VideoWriter_fourcc(*'mp4v'), fps, self.img_size)\n",
    "\n",
    "        vid_writer = cv2.VideoWriter(save_name,fourcc, 30.0, (640,480))\n",
    "\n",
    "        pil_clothes = self._preprocess_image(pil_clothes)\n",
    "\n",
    "        clothes = transform_image(pil_clothes)\n",
    "        if pil_edge is not None:\n",
    "            clothes_edge = self._preprocess_image(pil_clothes, color='L')\n",
    "            clothes_edge = transform_edge(clothes_edge)\n",
    "        else:\n",
    "            clothes_edge = self._predict_edge(clothes)\n",
    "\n",
    "        idx = 0\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if ret is True:\n",
    "                frame = frame[:, :, :]\n",
    "                cropped_result, frame = self._preprocess_frame(frame)\n",
    "                if frame is not None:\n",
    "                    pil_img = Image.fromarray(frame)\n",
    "                    img = transform_image(pil_img)\n",
    "\n",
    "                # TRYON\n",
    "                original_image = cropped_result['origin_frame']\n",
    "                if frame is not None:\n",
    "                    cv_img = (\n",
    "                        self._predict_tryon(img, clothes, clothes_edge)\n",
    "                        .permute(1, 2, 0)\n",
    "                        .detach()\n",
    "                        .cpu()\n",
    "                        .numpy()\n",
    "                        + 1\n",
    "                    ) / 2\n",
    "                    rgb = (cv_img * 255).astype(np.uint8)\n",
    "                    bgr = cv2.cvtColor(rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                    # Re-mapping to original image\n",
    "                    top, left, bottom, right = (\n",
    "                        cropped_result['top'],\n",
    "                        cropped_result['left'],\n",
    "                        cropped_result['bottom'],\n",
    "                        cropped_result['right'],\n",
    "                    )\n",
    "                    cropped_output = cv2.resize(bgr, (right - left, bottom - top))\n",
    "                    original_image[top:bottom, left:right, :] = cropped_output\n",
    "\n",
    "                idx += 1\n",
    "                # cv2.imwrite(f\"{idx}.jpg\", original_image)\n",
    "                vid_writer.write(original_image)\n",
    "                # vid_writer.write(frame)\n",
    "\n",
    "            else:\n",
    "                break\n",
    "        cap.release()\n",
    "        vid_writer.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def tryon_camera(self, pil_clothes, camera=None, pil_edge=None) -> Any:\n",
    "        \"\"\"Video streaming generator function.\"\"\"\n",
    "        if camera == None:\n",
    "            camera = cv2.VideoCapture(0)\n",
    "        transform_image = get_transform(train=False)\n",
    "        transform_edge = get_transform(train=False, method=Image.NEAREST, normalize=False)\n",
    "        pil_clothes = self._preprocess_image(pil_clothes)\n",
    "        clothes = transform_image(pil_clothes)\n",
    "        if pil_edge is not None:\n",
    "            clothes_edge = self._preprocess_image(pil_clothes, color='L')\n",
    "            clothes_edge = transform_edge(clothes_edge)\n",
    "        else:\n",
    "            clothes_edge = self._predict_edge(clothes)\n",
    "\n",
    "        while camera.isOpened():\n",
    "            success, frame = camera.get_frame()\n",
    "            if success is True:\n",
    "                frame = frame[:, :, :]\n",
    "                cropped_result, frame = self._preprocess_frame(frame)\n",
    "                if frame is not None:\n",
    "                    pil_img = Image.fromarray(frame)\n",
    "                    img = transform_image(pil_img)\n",
    "\n",
    "                # TRYON\n",
    "                original_image = cropped_result['origin_frame']\n",
    "                if frame is not None:\n",
    "                    cv_img = (\n",
    "                        self._predict_tryon(img, clothes, clothes_edge)\n",
    "                        .permute(1, 2, 0)\n",
    "                        .detach()\n",
    "                        .cpu()\n",
    "                        .numpy()\n",
    "                        + 1\n",
    "                    ) / 2\n",
    "                    rgb = (cv_img * 255).astype(np.uint8)\n",
    "                    bgr = cv2.cvtColor(rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                    # Re-mapping to original image\n",
    "                    top, left, bottom, right = (\n",
    "                        cropped_result['top'],\n",
    "                        cropped_result['left'],\n",
    "                        cropped_result['bottom'],\n",
    "                        cropped_result['right'],\n",
    "                    )\n",
    "                    cropped_output = cv2.resize(bgr, (right - left, bottom - top))\n",
    "                    original_image[top:bottom, left:right, :] = cropped_output\n",
    "                \n",
    "                cv2.imshow(\"Camera\", original_image)\n",
    "                key = cv2.waitKey(20)\n",
    "                if key == 27: # exit on ESC\n",
    "                    break\n",
    "                # ret, jpeg = cv2.imencode('.jpg', original_image)\n",
    "                # original_image = jpeg.tobytes()\n",
    "                # yield (b'--frame\\r\\n'\n",
    "                #     b'Content-Type: image/jpeg\\r\\n\\r\\n' + original_image + b'\\r\\n')\n",
    "        del camera\n",
    "        cv2.destroyAllWindows()\n",
    "            \n",
    "\n",
    "\n",
    "    def tryon_image(self, pil_img, pil_clothes, pil_edge=None) -> Any:\n",
    "        transform_image = get_transform(train=False)\n",
    "        transform_edge = get_transform(train=False, method=Image.NEAREST, normalize=False)\n",
    "\n",
    "        pil_img, pil_clothes = self._preprocess_image(pil_img), self._preprocess_image(pil_clothes)\n",
    "\n",
    "        img = transform_image(pil_img)\n",
    "        clothes = transform_image(pil_clothes)\n",
    "        if pil_edge:\n",
    "            clothes_edge = self._preprocess_image(pil_clothes, color='L')\n",
    "            clothes_edge = transform_edge(clothes_edge)\n",
    "        else:\n",
    "            clothes_edge = self._predict_edge(clothes)\n",
    "\n",
    "        return (self._predict_tryon(img, clothes, clothes_edge) + 1) / 2\n",
    "\n",
    "    def _preprocess_image(self, pil_img, color='RGB'):\n",
    "        pil_img = pil_img.convert(color).resize(self.img_size)\n",
    "        return pil_img\n",
    "\n",
    "    def _preprocess_frame(self, frame):\n",
    "        # Crop the image using pose\n",
    "        cropped_result = crop_upper_body(frame, self.yolo_model)\n",
    "        frame = cropped_result['cropped_frame']\n",
    "\n",
    "        if frame is None:\n",
    "            return cropped_result, None\n",
    "\n",
    "        # Crop the image to have same ratio\n",
    "        if frame.shape[0] * self.img_size[0] < frame.shape[1] * self.img_size[1]:\n",
    "            height = frame.shape[0]\n",
    "            width = int(self.img_size[0] * height / self.img_size[1])\n",
    "        else:\n",
    "            width = frame.shape[1]\n",
    "            height = int(self.img_size[1] * width / self.img_size[0])\n",
    "\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        center = (frame.shape[0] // 2, frame.shape[1] // 2)\n",
    "        x = center[1] - width // 2\n",
    "        y = center[0] - height // 2\n",
    "        frame = frame[y : y + height, x : x + width]\n",
    "        frame = cv2.resize(frame, (self.img_size[0], self.img_size[1]))\n",
    "\n",
    "        # Mapping bbox value\n",
    "        cropped_result['top'] += y\n",
    "        cropped_result['bottom'] = cropped_result['top'] + height\n",
    "        cropped_result['left'] += x\n",
    "        cropped_result['right'] = cropped_result['left'] + width\n",
    "\n",
    "        return cropped_result, frame\n",
    "\n",
    "    def _load_model(self, tryon_ckpt, edge_detect_ckpt, device):\n",
    "        self.tryon_model = DMVTON(tryon_ckpt, device=device, align_corners=True)\n",
    "        self.edge_detect_model = load_edge_detect_model(\n",
    "            model_name='u2netp', checkpoint=edge_detect_ckpt, device=device\n",
    "        )\n",
    "\n",
    "    def _load_yolov7(self, yolo_ckpt):\n",
    "        self.yolo_model = Yolov7PoseEstimation(\n",
    "            weight_path=yolo_ckpt,\n",
    "            device=self.device,\n",
    "        )\n",
    "\n",
    "    def _predict_edge(self, img):\n",
    "        img = img.clone().unsqueeze(0)\n",
    "        img = img.type(torch.FloatTensor)\n",
    "\n",
    "        img = Variable(img.to(self.device))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            d1 = self.edge_detect_model(img)\n",
    "\n",
    "        pred_mask = d1[:, 0, :, :]\n",
    "        pred_mask = norm_pred(pred_mask)\n",
    "\n",
    "        return pred_mask\n",
    "\n",
    "    def _predict_tryon(self, img, clothes, clothes_edge):\n",
    "        img = img.clone().unsqueeze(0)\n",
    "        clothes = clothes.clone().unsqueeze(0)\n",
    "        clothes_edge = clothes_edge.clone().unsqueeze(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            p_tryon = self.tryon_model(img, clothes, clothes_edge)\n",
    "\n",
    "        return p_tryon[0]\n",
    "\n",
    "\n",
    "def crop_upper_body(frame, pose_detector):\n",
    "    results = pose_detector.process(frame)\n",
    "    h, w, _ = frame.shape\n",
    "\n",
    "    # TUNGPNT2\n",
    "    if results.pose_landmarks is None:\n",
    "        return {\n",
    "            'origin_frame': frame,\n",
    "            'cropped_frame': None,\n",
    "            'top': 0,\n",
    "            'left': 0,\n",
    "            'bottom': 0,\n",
    "            'right': 0,\n",
    "        }\n",
    "\n",
    "    landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "    # 2 lower points of upper body\n",
    "    l1 = {'x': landmarks[23].x, 'y': landmarks[23].y}\n",
    "    l2 = {'x': landmarks[24].x, 'y': landmarks[24].y}\n",
    "\n",
    "    # 2 eyes\n",
    "    e1 = {'x': landmarks[2].x, 'y': landmarks[2].y}\n",
    "    e2 = {'x': landmarks[5].x, 'y': landmarks[5].y}\n",
    "\n",
    "    points = [l1, l2, e1, e2]\n",
    "\n",
    "    # bbox\n",
    "    top = min([i['y'] for i in points])\n",
    "    bottom = max([i['y'] for i in points])\n",
    "    left = min([i['x'] for i in points])\n",
    "    right = max([i['x'] for i in points])\n",
    "\n",
    "    # de-normalize\n",
    "    top = int(top * h)\n",
    "    bottom = int(bottom * h)\n",
    "    left = int(left * w)\n",
    "    right = int(right * w)\n",
    "\n",
    "    # padding\n",
    "    bh = bottom - top\n",
    "    bw = right - left\n",
    "    bottom += bh // 5\n",
    "    top -= bh // 5\n",
    "    right += bw // 1\n",
    "    left -= bw // 1\n",
    "\n",
    "    # crop\n",
    "    top = max(0, min(top, h))\n",
    "    bottom = max(0, min(bottom, h))\n",
    "    left = max(0, min(left, w))\n",
    "    right = max(0, min(right, w))\n",
    "\n",
    "    return {\n",
    "        'origin_frame': frame,\n",
    "        'cropped_frame': frame[top:bottom, left:right, :],\n",
    "        'top': top,\n",
    "        'left': left,\n",
    "        'bottom': bottom,\n",
    "        'right': right,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try-on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"./model\"\n",
    "model = TryonService(\n",
    "    tryon_ckpt={'warp': f'{prefix}/mobile_warp.pt', 'gen': f'{prefix}/mobile_gen.pt'},\n",
    "    edge_detect_ckpt=f'{prefix}/u2netp.pt',\n",
    "    yolo_ckpt=f'{prefix}/yolov7-w6-pose.pt',\n",
    "    device='cuda:0',\n",
    ")\n",
    "\n",
    "pil_clothes = Image.open(\n",
    "    \"./000097_1.jpg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try-on camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = Camera()\n",
    "with torch.no_grad():\n",
    "    model.tryon_camera(pil_clothes, camera)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try-on Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"./Test_persion.mp4\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.tryon_video(\"cap.mp4\", cap, pil_clothes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kisekloset",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
